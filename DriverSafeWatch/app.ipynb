{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Werkzeug appears to be used in a production deployment. Consider switching to a production web server instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:05] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:05] \"GET /static/tropical-10201.gif HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:05] \"GET /socket.io/?EIO=4&transport=polling&t=PAWZ0jh HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:05] \"GET /drum-bass-243588.mp3 HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:05] \"POST /socket.io/?EIO=4&transport=polling&t=PAWZ0kn&sid=MPfEkrxdztfVaXHLAAAA HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:05] \"GET /socket.io/?EIO=4&transport=polling&t=PAWZ0ko&sid=MPfEkrxdztfVaXHLAAAA HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:05] \"GET /socket.io/?EIO=4&transport=polling&t=PAWZ0os&sid=MPfEkrxdztfVaXHLAAAA HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:06] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.0133679  0.98663217]]\n",
      "person is not wearing a seatbelt\n",
      "Predictions: [[5.910841e-05 9.999409e-01]]\n",
      "person is not wearing a seatbelt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Oct/2024 22:23:32] \"GET /send_alert/You%20are%20too%20sleepy! HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message sent\n",
      "Predictions: [[4.0529931e-06 9.9999595e-01]]\n",
      "person is not wearing a seatbelt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Oct/2024 22:23:44] \"POST /terminate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2024 22:23:46] \"GET /socket.io/?EIO=4&transport=websocket&sid=MPfEkrxdztfVaXHLAAAA HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response, render_template, jsonify\n",
    "from flask_socketio import SocketIO\n",
    "import cv2\n",
    "import dlib\n",
    "import atexit\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "socketio = SocketIO(app)\n",
    "model = tf.keras.models.load_model('resnet50_seatbelt_model_checkpoint_epoch_12.h5')\n",
    "\n",
    "# Initialize video capture and models\n",
    "video_capture = cv2.VideoCapture(0)  # Use the default camera\n",
    "face_model = dlib.get_frontal_face_detector()\n",
    "landmark_model = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# File to keep track of trips and alerts\n",
    "TRIP_COUNT_FILE = 'trip_count.txt'\n",
    "ALERTS_FILE = 'alerts.txt'\n",
    "RECORDINGS_FOLDER = 'recordings'\n",
    "\n",
    "# Global flag to indicate if the camera is active\n",
    "camera_active = True\n",
    "video_writer = None  # To hold the VideoWriter object\n",
    "\n",
    "# Initialize trip counter\n",
    "def initialize_trip_counter():\n",
    "    if not os.path.exists(TRIP_COUNT_FILE):\n",
    "        with open(TRIP_COUNT_FILE, 'w') as file:\n",
    "            file.write('0')  # Start from trip 0\n",
    "\n",
    "# Function to get the current trip number\n",
    "def get_trip_number():\n",
    "    with open(TRIP_COUNT_FILE, 'r') as file:\n",
    "        trip_number = int(file.read().strip())  # Read the current trip number\n",
    "    return trip_number\n",
    "def predict_seatbelt(frame, target_size=(120, 160), threshold=0.5):\n",
    "    # Resize the image to match the model's input shape\n",
    "    image = cv2.resize(frame, target_size)\n",
    "    \n",
    "    # Convert the image to a floating-point array and scale pixel values to [0, 1]\n",
    "    image = image.astype('float32') / 255.0\n",
    "    \n",
    "    # Add a batch dimension\n",
    "    input_image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Make a prediction\n",
    "    predictions = model.predict(input_image)\n",
    "\n",
    "    # Print the predictions\n",
    "    print(\"Predictions:\", predictions)\n",
    "\n",
    "    if predictions[0,0]>predictions[0,1]:\n",
    "       return \"person is wearing a seatbelt\"\n",
    "    else:\n",
    "       return \"person is not wearing a seatbelt\"\n",
    "def increment_trip_number():\n",
    "    trip_number = get_trip_number() + 1  # Increment trip number\n",
    "    with open(TRIP_COUNT_FILE, 'w') as file:\n",
    "        file.write(str(trip_number))  # Save the updated trip number\n",
    "    return trip_number\n",
    "\n",
    "# Function to save alerts to a text file\n",
    "def save_alert_to_file(message, timestamp):\n",
    "    with open(ALERTS_FILE, 'a') as file:\n",
    "        file.write(f\"{timestamp}: {message}\\n\")\n",
    "\n",
    "# Function to log the trip start time\n",
    "def log_trip_start(trip_number):\n",
    "    start_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(ALERTS_FILE, 'a') as file:\n",
    "        file.write(f\"Trip {trip_number+1} started at: {start_time}\\n\")\n",
    "\n",
    "# Function to log the trip end time\n",
    "def log_trip_end(trip_number):\n",
    "    end_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(ALERTS_FILE, 'a') as file:\n",
    "        file.write(f\"Trip {trip_number+1} ended at: {end_time}\\n\")\n",
    "\n",
    "# Thresholds for yawn detection\n",
    "yawn_min_thresh = 7\n",
    "yawn_max_thresh = 20\n",
    "\n",
    "# Drowsiness detection thresholds\n",
    "EYE_ASPECT_RATIO_THRESHOLD = 0.25\n",
    "EYE_ASPECT_RATIO_CONSEC_FRAMES = 30\n",
    "COUNTER = 0\n",
    "drowsiness_detected = False\n",
    "drowsiness_count = 0\n",
    "\n",
    "# Extract indexes of facial landmarks for the left and right eye\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS['left_eye']\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS['right_eye']\n",
    "\n",
    "# Function to calculate eye aspect ratio (EAR)\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2 * C)\n",
    "    return ear\n",
    "\n",
    "# Function to calculate mouth aspect ratio (MAR)\n",
    "def mouth_aspect_ratio(top_lip_point, bottom_lip_point, left_corner, right_corner):\n",
    "    vertical_distance = bottom_lip_point[1] - top_lip_point[1]\n",
    "    horizontal_distance = right_corner[0] - left_corner[0]\n",
    "    mar = vertical_distance / horizontal_distance\n",
    "    return mar\n",
    "\n",
    "# Variables for yawning detection\n",
    "yawn_detected = False\n",
    "yawn_count = 0\n",
    "mouth_aspect_ratios = []  # List to store MAR over frames for smoothing\n",
    "\n",
    "# Generate frames for video feed\n",
    "def generate_frames():\n",
    "    yawn_count = 0\n",
    "    drowsiness_count = 0\n",
    "    global camera_active, video_writer\n",
    "    trip_number = get_trip_number()  # Get the current trip number\n",
    "    log_trip_start(trip_number)  # Log the trip start time\n",
    "\n",
    "    # Create the recordings directory if it doesn't exist\n",
    "    if not os.path.exists(RECORDINGS_FOLDER):\n",
    "        os.makedirs(RECORDINGS_FOLDER)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "    video_file_path = os.path.join(RECORDINGS_FOLDER, f'trip_{trip_number+1}.mp4')\n",
    "    video_writer = cv2.VideoWriter(video_file_path, fourcc, 20.0, (640, 480))  # Change frame size as needed\n",
    "    \n",
    "    last_frame_time = time.time()\n",
    "    while camera_active:\n",
    "        success, frame = video_capture.read()\n",
    "        if not success:\n",
    "            break\n",
    "        current_time = time.time()\n",
    "        if current_time - last_frame_time >= 10:\n",
    "            last_frame_time = current_time  # Update the last frame time\n",
    "            \n",
    "            # Predict seatbelt status\n",
    "            seatbelt_alert = predict_seatbelt(frame)\n",
    "            print(seatbelt_alert)  # Call the prediction on the current frame\n",
    "\n",
    "            # Emit seatbelt alert if the person is not wearing a seatbelt\n",
    "            if seatbelt_alert == \"person is not wearing a seatbelt\":\n",
    "                socketio.emit('alert', {'message': seatbelt_alert})  # Send the seatbelt alert to the frontend\n",
    "\n",
    "        img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_model(img_gray)\n",
    "\n",
    "        for face in faces:\n",
    "            shapes = landmark_model(img_gray, face)\n",
    "            shape = face_utils.shape_to_np(shapes)\n",
    "\n",
    "            # Yawn Detection (MAR)\n",
    "            top_lip_point = shape[51]  # Top midpoint of the upper lip\n",
    "            bottom_lip_point = shape[57]  # Bottom midpoint of the lower lip\n",
    "            left_corner = shape[48]\n",
    "            right_corner = shape[54]\n",
    "\n",
    "            mar = mouth_aspect_ratio(top_lip_point, bottom_lip_point, left_corner, right_corner)\n",
    "            mouth_aspect_ratios.append(mar)\n",
    "\n",
    "            if len(mouth_aspect_ratios) > 10:  # Only keep the last 10 values for smoothing\n",
    "                mouth_aspect_ratios.pop(0)\n",
    "            avg_mar = np.mean(mouth_aspect_ratios)\n",
    "\n",
    "            if avg_mar >= 0.5:  # Threshold for yawning\n",
    "                if not yawn_detected:\n",
    "                    yawn_detected = True\n",
    "                    yawn_count += 1\n",
    "            else:\n",
    "                yawn_detected = False\n",
    "\n",
    "            # Drowsiness Detection (EAR)\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEyeAspectRatio = eye_aspect_ratio(leftEye)\n",
    "            rightEyeAspectRatio = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEyeAspectRatio + rightEyeAspectRatio) / 2\n",
    "\n",
    "            if ear < EYE_ASPECT_RATIO_THRESHOLD:\n",
    "                COUNTER += 1\n",
    "                if COUNTER >= EYE_ASPECT_RATIO_CONSEC_FRAMES:\n",
    "                    if not drowsiness_detected:\n",
    "                        drowsiness_detected = True\n",
    "                        drowsiness_count += 1\n",
    "                    cv2.putText(frame, \"Drowsy!\", (150, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2)\n",
    "            else:\n",
    "                COUNTER = 0\n",
    "                drowsiness_detected = False\n",
    "\n",
    "            # Send alert if counts exceed 2\n",
    "            if yawn_count > 2 or drowsiness_count > 2:\n",
    "                socketio.emit('alert', {'message': 'You are too sleepy!'})\n",
    "                yawn_count = 0\n",
    "                drowsiness_count = 0\n",
    "\n",
    "            # Write the frame to the video file\n",
    "            video_writer.write(frame)\n",
    "\n",
    "            # Convert the frame to JPEG format\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "\n",
    "            # Yield the frame as a byte-stream\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "    # If the loop breaks, log the trip end\n",
    "    log_trip_end(trip_number)  # Log the trip end\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "# Route to receive alerts\n",
    "@app.route('/send_alert/<message>')\n",
    "def send_alert(message):\n",
    "    if camera_active:\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        save_alert_to_file(message, timestamp)\n",
    "        return \"Alert received!\", 200\n",
    "    else:\n",
    "        return \"Camera is closed. Alert not saved.\", 400\n",
    "\n",
    "# Route to handle termination\n",
    "@app.route('/terminate', methods=['POST'])\n",
    "def terminate():\n",
    "    global camera_active, video_writer\n",
    "    camera_active = False  # Set camera active to false\n",
    "    release_camera()  # Release the camera resources\n",
    "    increment_trip_number()  # Increment trip number on termination\n",
    "    return jsonify({\"status\": \"Terminated\"})\n",
    "\n",
    "# Function to release camera and writer resources\n",
    "def release_camera():\n",
    "    global video_capture, video_writer\n",
    "    if video_capture.isOpened():\n",
    "        video_capture.release()\n",
    "    if video_writer is not None:\n",
    "        video_writer.release()\n",
    "\n",
    "# Ensure resources are released when the program exits\n",
    "atexit.register(release_camera)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    initialize_trip_counter()\n",
    "    socketio.run(app, debug=False,allow_unsafe_werkzeug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bharath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
